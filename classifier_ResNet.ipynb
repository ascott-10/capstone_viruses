{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Using ResNet\n",
    "\n",
    "https://medium.com/@kirudang/deep-learning-computer-vision-using-transfer-learning-resnet-18-in-pytorch-skin-cancer-8d5b158893c5\n",
    "\n",
    "let's not reinvent the wheel over here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Setup deep learning environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cu124\n",
      "cuda\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Check version of Pytorch\n",
    "print(torch. __version__)\n",
    "\n",
    "# Setup device agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# Find out if a GPU is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ascott10/micromamba/envs/caps/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ascott10/micromamba/envs/caps/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#Load the pre-trained ResNet-18 model\n",
    "model = models.resnet18(pretrained = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Step 2: Freeze the pretrained layers\n",
    "\n",
    "#Only train the last few layers for our specific task\n",
    "#Prevents weights of pre-trained layers from being updated during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Freeze all the pre-trained layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Step 3: Modify the last layer\n",
    "#The last layer is a fully connected layer that outputs a 1000-dim vector\n",
    "#Need to modify to output the # of classes in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modify the last layer of the model\n",
    "num_classes = 2 #replace with number of classes in dataset\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Load the custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_path</th>\n",
       "      <th>class</th>\n",
       "      <th>im_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/ascott10/documents/school/capstone/mutan...</td>\n",
       "      <td>mutant</td>\n",
       "      <td>A2_MHV_AxA_0005_Ceta_578_912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/ascott10/documents/school/capstone/mutan...</td>\n",
       "      <td>mutant</td>\n",
       "      <td>A2_MHV_AxA_0021_Ceta_2087_954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/ascott10/documents/school/capstone/mutan...</td>\n",
       "      <td>mutant</td>\n",
       "      <td>A2_MHV_AxA_0082_Ceta_3176_566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/ascott10/documents/school/capstone/mutan...</td>\n",
       "      <td>mutant</td>\n",
       "      <td>A2_MHV_AxA_0058_Ceta_3477_1554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/ascott10/documents/school/capstone/mutan...</td>\n",
       "      <td>mutant</td>\n",
       "      <td>A2_MHV_AxA_0085_Ceta_1241_3163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>/home/ascott10/documents/school/capstone/wt/MH...</td>\n",
       "      <td>wt</td>\n",
       "      <td>MHVWT_A70021_879_399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>/home/ascott10/documents/school/capstone/wt/MH...</td>\n",
       "      <td>wt</td>\n",
       "      <td>MHVWT_A70053_2141_2078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>/home/ascott10/documents/school/capstone/wt/MH...</td>\n",
       "      <td>wt</td>\n",
       "      <td>MHVWT_A70020_2528_277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>/home/ascott10/documents/school/capstone/wt/MH...</td>\n",
       "      <td>wt</td>\n",
       "      <td>MHVWT_A70036_3386_1367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>/home/ascott10/documents/school/capstone/wt/MH...</td>\n",
       "      <td>wt</td>\n",
       "      <td>MHVWT_A70033_956_861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>929 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             file_path   class  \\\n",
       "0    /home/ascott10/documents/school/capstone/mutan...  mutant   \n",
       "1    /home/ascott10/documents/school/capstone/mutan...  mutant   \n",
       "2    /home/ascott10/documents/school/capstone/mutan...  mutant   \n",
       "3    /home/ascott10/documents/school/capstone/mutan...  mutant   \n",
       "4    /home/ascott10/documents/school/capstone/mutan...  mutant   \n",
       "..                                                 ...     ...   \n",
       "924  /home/ascott10/documents/school/capstone/wt/MH...      wt   \n",
       "925  /home/ascott10/documents/school/capstone/wt/MH...      wt   \n",
       "926  /home/ascott10/documents/school/capstone/wt/MH...      wt   \n",
       "927  /home/ascott10/documents/school/capstone/wt/MH...      wt   \n",
       "928  /home/ascott10/documents/school/capstone/wt/MH...      wt   \n",
       "\n",
       "                              im_id  \n",
       "0      A2_MHV_AxA_0005_Ceta_578_912  \n",
       "1     A2_MHV_AxA_0021_Ceta_2087_954  \n",
       "2     A2_MHV_AxA_0082_Ceta_3176_566  \n",
       "3    A2_MHV_AxA_0058_Ceta_3477_1554  \n",
       "4    A2_MHV_AxA_0085_Ceta_1241_3163  \n",
       "..                              ...  \n",
       "924            MHVWT_A70021_879_399  \n",
       "925          MHVWT_A70053_2141_2078  \n",
       "926           MHVWT_A70020_2528_277  \n",
       "927          MHVWT_A70036_3386_1367  \n",
       "928            MHVWT_A70033_956_861  \n",
       "\n",
       "[929 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#input folder paths\n",
    "input_path_mut = '/home/ascott10/documents/school/capstone/mutant'\n",
    "input_path_wt = '/home/ascott10/documents/school/capstone/wt'\n",
    "\n",
    "#Retrieve files\n",
    "image_filepaths_mut = []\n",
    "image_mut_labels = []\n",
    "image_mut_id = []\n",
    "image_filepaths_wt = []\n",
    "image_wt_labels = []\n",
    "image_wt_id = []\n",
    "\n",
    "\n",
    "#for each file in the inputs add path to storage list:\n",
    "\n",
    "for files in os.listdir(input_path_mut):\n",
    "    if files.endswith('png'):\n",
    "        image_filepaths_mut.append(os.path.join(input_path_mut,files))\n",
    "        image_mut_labels.append('mutant')\n",
    "        image_mut_id.append(Path(files).parts[-1][:-4])\n",
    "\n",
    "for files in os.listdir(input_path_wt):\n",
    "    if files.endswith('png'):\n",
    "        image_filepaths_wt.append(os.path.join(input_path_wt,files))\n",
    "        image_wt_labels.append('wt')\n",
    "        image_wt_id.append(Path(files).parts[-1][:-4])\n",
    "\n",
    "mutant_df = pd.DataFrame([image_filepaths_mut, image_mut_labels, image_mut_id], index= ['file_path', 'class', 'im_id']).T\n",
    "\n",
    "wt_df = pd.DataFrame([image_filepaths_wt, image_wt_labels, image_wt_id], index= ['file_path', 'class', 'im_id']).T\n",
    "\n",
    "wt_df\n",
    "\n",
    "all_files_df = pd.concat([mutant_df, wt_df], ignore_index=True)\n",
    "\n",
    "all_files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_df, X_test_df = train_test_split(all_files_df,test_size = 0.2)\n",
    "X_train_df, X_val_df = train_test_split(X_train_df,test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import cv2\n",
    "\n",
    "#Define the transformations to apply to the images\n",
    "\n",
    "\n",
    "# Define transformations (for PyTorch)\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to PyTorch tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize\n",
    "])\n",
    "\n",
    "#Function to process df to tensors\n",
    "\n",
    "def create_tensor_dataset(df):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        #for file_path, class\n",
    "        file_path, label = row[0], row[1]\n",
    "\n",
    "        #open the image and convert\n",
    "        img = cv2.imread(file_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv2.resize(img, (256,256))\n",
    "\n",
    "        img = transform(img) #Apply Pytorch transforms\n",
    "\n",
    "        images.append(img)\n",
    "        labels.append(int(1) if label == 'mutant' else int(0)) #convert labels to ints\n",
    "\n",
    "    #lists to tensorts\n",
    "    images_tensor = torch.stack(images)\n",
    "    labels_tensor = torch.tensor(labels, dtype = torch.long)\n",
    "\n",
    "    return TensorDataset(images_tensor, labels_tensor)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3097/539256888.py:22: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  file_path, label = row[0], row[1]\n"
     ]
    }
   ],
   "source": [
    "#Create datasets\n",
    "train_dataset = create_tensor_dataset(X_train_df)\n",
    "val_dataset = create_tensor_dataset(X_val_df)\n",
    "test_dataset = create_tensor_dataset(X_test_df)\n",
    "\n",
    "#Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle = False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Step 5: Define the loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Define the loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(),\n",
    "                             lr = 0.001)\n",
    "                             \n",
    "\n",
    "\n",
    "#Use Pytorch DataLoader and TrainLoader utilities\n",
    "\n",
    "#Create Data Loaders for the train and validation datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
    "    # Train the model for the specified number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set the model to train mode\n",
    "        model.train()\n",
    "\n",
    "        # Initialize the running loss and accuracy\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over the batches of the train loader\n",
    "        for inputs, labels in train_loader:\n",
    "            # Move the inputs and labels to the device\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Zero the optimizer gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimizer step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Update the running loss and accuracy\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Calculate the train loss and accuracy\n",
    "        train_loss = running_loss / len(train_dataset)\n",
    "        train_acc = running_corrects.double() / len(train_dataset)\n",
    "\n",
    "        # Set the model to evaluation mode\n",
    "        model.eval()\n",
    "\n",
    "        # Initialize the running loss and accuracy\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over the batches of the validation loader\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                # Move the inputs and labels to the device\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # Update the running loss and accuracy\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        # Calculate the validation loss and accuracy\n",
    "        val_loss = running_loss / len(val_dataset)\n",
    "        val_acc = running_corrects.double() / len(val_dataset)\n",
    "\n",
    "        # Print the epoch results\n",
    "        print('Epoch [{}/{}], train loss: {:.4f}, train acc: {:.4f}, val loss: {:.4f}, val acc: {:.4f}'\n",
    "              .format(epoch+1, num_epochs, train_loss, train_acc, val_loss, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Fine-tune the model on the custom dataset\n",
    "Train the last layer for a few epochs, then unfreeze all layers and train the entire network for a few more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], train loss: 0.8480, train acc: 0.7325, val loss: 0.5585, val acc: 0.7097\n",
      "Epoch [2/5], train loss: 0.3576, train acc: 0.8528, val loss: 0.5871, val acc: 0.7312\n",
      "Epoch [3/5], train loss: 0.2463, train acc: 0.9066, val loss: 1.2713, val acc: 0.6022\n",
      "Epoch [4/5], train loss: 0.3393, train acc: 0.8671, val loss: 0.3359, val acc: 0.8495\n",
      "Epoch [5/5], train loss: 0.1753, train acc: 0.9210, val loss: 0.2219, val acc: 0.9355\n"
     ]
    }
   ],
   "source": [
    "#Set the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "#Fine tune the last layer for a few epochs\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr = 0.01)\n",
    "train(model, train_loader, val_loader, criterion, optimizer, num_epochs=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], train loss: 0.7365, train acc: 0.8582, val loss: 15.8195, val acc: 0.5645\n",
      "Epoch [2/10], train loss: 0.1574, train acc: 0.9533, val loss: 0.7265, val acc: 0.8602\n",
      "Epoch [3/10], train loss: 0.0730, train acc: 0.9749, val loss: 0.1267, val acc: 0.9624\n",
      "Epoch [4/10], train loss: 0.0127, train acc: 0.9982, val loss: 0.1032, val acc: 0.9516\n",
      "Epoch [5/10], train loss: 0.0087, train acc: 0.9964, val loss: 0.1382, val acc: 0.9570\n",
      "Epoch [6/10], train loss: 0.0457, train acc: 0.9820, val loss: 0.1330, val acc: 0.9409\n",
      "Epoch [7/10], train loss: 0.1146, train acc: 0.9623, val loss: 0.4463, val acc: 0.9140\n",
      "Epoch [8/10], train loss: 0.0496, train acc: 0.9803, val loss: 0.8140, val acc: 0.8387\n",
      "Epoch [9/10], train loss: 0.0078, train acc: 0.9964, val loss: 0.1017, val acc: 0.9570\n",
      "Epoch [10/10], train loss: 0.0053, train acc: 0.9982, val loss: 0.3904, val acc: 0.9194\n"
     ]
    }
   ],
   "source": [
    "#Freeze all layers and fine tune the entire network for a few more epochs\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "train(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"resnet_weights.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ascott10/micromamba/envs/caps/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/ascott10/micromamba/envs/caps/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reinitialize\n",
    "model = models.resnet18(pretrained = False) #loading custom weights\n",
    "\n",
    "#Modify the last layer\n",
    "num_features = model.fc.in_features\n",
    "model.fc = torch.nn.Linear(num_features,2)\n",
    "\n",
    "#Load trained weights\n",
    "model.load_state_dict(torch.load('resnet_weights.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 95.16%\n",
      "Confusion Matrix: \n",
      " [[94  9]\n",
      " [ 0 83]]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions = []\n",
    "correct = 0  # Initialize correct count\n",
    "total = 0    # Initialize total count\n",
    "\n",
    "with torch.no_grad():  \n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to same device as model\n",
    "        \n",
    "        outputs = model(images)  \n",
    "        _, predicted = torch.max(outputs, 1)  \n",
    "\n",
    "        predictions.extend(predicted.tolist())  # Store predictions\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate Accuracy\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Copy test dataframe\n",
    "X_test_df_preds = X_test_df.copy()\n",
    "\n",
    "# Assign predicted labels\n",
    "X_test_df_preds[\"predicted_label\"] = [\"mutant\" if p == 1 else \"wt\" for p in predictions]\n",
    "\n",
    "# Print Confusion Matrix\n",
    "print(f\"Confusion Matrix: \\n {confusion_matrix(X_test_df_preds['class'], X_test_df_preds['predicted_label'])}\")\n",
    "\n",
    "# Drop file_path column\n",
    "X_test_df_preds = X_test_df_preds.drop('file_path', axis=1)\n",
    "\n",
    "# Get the confusion matrix\n",
    "cf_matrix = confusion_matrix(X_test_df_preds['class'], X_test_df_preds['predicted_label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define class labels\n",
    "labels = [\"wildtype\", \"mutant\"]\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='d', cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
